#!/bin/bash

#SBATCH -A BIF146
#SBATCH -J ddp
##SBATCH -o ddp-%j.o
##SBATCH -e ddp-%j.e
#SBATCH -t 02:00:00
#SBATCH -p batch
#SBATCH -N 2

set +x
source /lustre/orion/proj-shared/stf006/irl1/conda/etc/profile.d/conda.sh
conda activate /lustre/orion/bif146/world-shared/irl1/NNUNETENV

export nnUNet_raw_data_base=/lustre/orion/bif146/proj-shared/irl1/raw_data
export nnUNet_preprocessed=/lustre/orion/bif146/proj-shared/irl1/preprocessed_data
#export nnUNet_preprocessed=/lustre/orion/bif146/proj-shared/irl1/preprocessed_data/bigger
export RESULTS_FOLDER=/lustre/orion/bif146/proj-shared/irl1/RESULTS

module load rocm/6.0.0

source export_DDP_envvars.sh

ranks_per_node=8
gpus_per_rank=$((8/$ranks_per_node))
ranks_total=$(($ranks_per_node*$SLURM_JOB_NUM_NODES))

export OMP_NUM_THREADS=1

#CPU Threading of unpacing npz files -- Not done, consider adding
#export nnUNet_def_n_proc=1
#Default value of data augmentation threads = 12, needs testing
#export nnUNet_n_proc_DA=4

#export NCCL_SOCKET_IFNAME=hsn
#export NCCL_PROTO=Simple
#export NCCL_DEBUG=info
#export FI_CXI_ATS=0
#export FI_LOG_LEVEL=info
export LD_LIBRARY_PATH=/lustre/orion/bif146/world-shared/irl1/aws-ofi-rccl-2/src/.libs/:${LD_LIBRARY_PATH}
export NCCL_NET_GDR_LEVEL=3
export FI_MR_CACHE_MONITOR=userfaultfd

# 7 cpus-per-task because 1 cpu kept for OS
#MIOPEN_DISABLE_CACHE=1 MIOPEN_CUSTOM_CACHE_DIR='pwd' HOME=/tmp/ srun -n $ranks_total -c 7 --ntasks-per-node=8 python nnunet/run/run_training_DDP.py 3d_fullres nnUNetTrainerV2_DDP Task934_MBrainLat_dup 0 -run_name 8_node_scale_dup_dist_aws_singleThread --master_addr=$MASTER_ADDR
MIOPEN_DISABLE_CACHE=1 MIOPEN_CUSTOM_CACHE_DIR='pwd' HOME=/tmp/ srun -n $ranks_total -c 7 --ntasks-per-node=8 python nnunet/run/run_training_DDP.py 3d_fullres nnUNetTrainerV2_DDP Task933_MBrainLat 0 -run_name test_1_600_TESTY --master_addr=$MASTER_ADDR
