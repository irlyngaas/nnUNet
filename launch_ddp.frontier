#!/bin/bash

#SBATCH -A STF006
#SBATCH -J ddp
#SBATCH -o ddp-%j.o
#SBATCH -e ddp-%j.e
#SBATCH -t 02:00:00
#SBATCH -p batch
#SBATCH -N 128

set +x
source /lustre/orion/proj-shared/stf006/irl1/conda/etc/profile.d/conda.sh
conda activate /lustre/orion/stf006/proj-shared/irl1/t2
export LD_PRELOAD="/usr/lib64/libcrypto.so /usr/lib64/libssh.so.4 /usr/lib64/libssl.so.1.1"

export nnUNet_raw_data_base=/lustre/orion/stf006/proj-shared/irl1/raw_data
export nnUNet_preprocessed=/lustre/orion/stf006/proj-shared/irl1/preprocessed_data
export RESULTS_FOLDER=/lustre/orion/stf006/proj-shared/irl1/RESULTS

module load PrgEnv-gnu
module load gcc/11.2.0
module load rocm/5.4.0

# setup hostfile
HOSTS=.hosts-job$SLURM_JOB_ID
HOSTFILE=hostfile.txt
srun hostname > $HOSTS
sed 's/$/ slots=8/' $HOSTS > $HOSTFILE

scontrol show hostnames $SLURM_NODELIST > job.node.list
input="./job.node.list"
readarray -t arr <"$input"
first=${arr[0]}
echo "first=" $first
ips=`ssh $first hostname -I`
read -ra arr <<< ${ips}
export MASTER_ADDR=${arr[0]}
echo "MASTER_ADDR=" $MASTER_ADDR

ranks_per_node=8
gpus_per_rank=$((8/$ranks_per_node))
ranks_total=$(($ranks_per_node*$SLURM_JOB_NUM_NODES))

#64 core total (w/ 2 hw threads per core)
#4 cpu_rank x 8 = 32 * 2 OMP thread = 64 
#Need to test this configuration
#Don't think changing to 2 matters
export OMP_NUM_THREADS=1

#CPU Threading of unpacing npz files -- Not done, consider adding
#export nnUNet_def_n_proc=1
#Default value of data augmentation threads = 12, needs testing
#export nnUNet_n_proc_DA=4

#export NCCL_SOCKET_IFNAME=hsn
#export NCCL_PROTO=Simple
#export NCCL_DEBUG=info
#export FI_CXI_ATS=0
#export LD_LIBRARY_PATH=/opt/rocm-5.4.0/rccl/build:$PWD/../aws-ofi-rccl/src/.libs/:/opt/cray/libfabric/1.15.2.0/lib64/:/opt/rocm-5.4.0/lib
#export FI_LOG_LEVEL=info
#export NCCL_NET_GDR_LEVEL=3

# 7 cpus-per-task because 1 cpu kept for OS
#MIOPEN_DISABLE_CACHE=1 MIOPEN_CUSTOM_CACHE_DIR='pwd' HOME=/tmp/ srun -n $ranks_total -c 7 --ntasks-per-node=8 python nnunet/run/run_training_DDP.py 3d_fullres nnUNetTrainerV2_DDP Task934_MBrainLat_dup 0 -run_name 8_node_scale_dup_dist_aws_singleThread --master_addr=$MASTER_ADDR
MIOPEN_DISABLE_CACHE=1 MIOPEN_CUSTOM_CACHE_DIR='pwd' HOME=/tmp/ srun -n $ranks_total -c 7 --ntasks-per-node=8 python nnunet/run/run_training_DDP.py 3d_fullres nnUNetTrainerV2_DDP Task933_MBrainLat 0 -run_name 128_node_scale_unpack --master_addr=$MASTER_ADDR
